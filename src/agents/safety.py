from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.state import MagazineState
from src.config import config

def run_safety(state: MagazineState) -> dict:
    print("--- [2] Safety Filter: ìœ í•´ì„± ê²€ì‚¬ ì¤‘... ---")
    llm = config.get_llm()
    
    # í”„ë¡¬í”„íŠ¸: ë„Œ ë³´ì•ˆê´€ì´ì•¼.
    prompt = ChatPromptTemplate.from_template(
        """
        Check the following text for PII (Personally Identifiable Information), hate speech, sexual content, or dangerous instructions.
        
        Text: {user_input}
        
        If safe, return "SAFE".
        If unsafe, return "UNSAFE" and a brief reason.
        """
    )
    
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({"user_input": state["user_input"]}).strip()
    
    is_safe = "SAFE" in result
    print(f"ğŸ›¡ï¸ ì•ˆì „ì„± ê²°ê³¼: {result}")

    return {
        "safety_check": "SAFE" if is_safe else "UNSAFE",
        "logs": [f"Safety: {result}"]
    }
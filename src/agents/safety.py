from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.state import MagazineState
from src.config import config
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
import re

# [ì¶”ê°€] ì¶œë ¥ êµ¬ì¡° ì •ì˜
class SafetyCheck(BaseModel):
    is_safe: bool = Field(description="ìœ í•´ì„± ì—¬ë¶€ (True: ì•ˆì „, False: ìœ„í—˜)")
    reason: str = Field(description="ìœ„í—˜ íŒë‹¨ ì´ìœ  (ì•ˆì „í•  ê²½ìš° 'None')")
    pii_detected: list = Field(description="ê²€ì¶œëœ ê°œì¸ì •ë³´ í•­ëª©ë“¤")

def run_safety(state: MagazineState) -> dict:
    print("--- [2] Safety Filter: ìœ í•´ì„± ê²€ì‚¬ ì¤‘... ---")
    llm = config.get_llm()

    # 1. Pydantic Parser ì„¤ì •: LLMì´ JSON í˜•ì‹ì„ ì§€í‚¤ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.
    parser = PydanticOutputParser(pydantic_object=SafetyCheck)
    
    user_input = state.get("user_input", "") 

    # 2. ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•œ ì‚¬ì „ PII ê²€ì‚¬ (Email, Phone ë“±)
    email_pattern = r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
    found_emails = re.findall(email_pattern, user_input)

    # 3. í”„ë¡¬í”„íŠ¸ ìˆ˜ì • 
    # - {format_instructions}ë¥¼ ì¶”ê°€í•˜ì—¬ LLMì—ê²Œ ì •í™•í•œ JSON êµ¬ì¡°ë¥¼ ì „ë‹¬
    # - ë‹¨ìˆœ "SAFE" ë°˜í™˜ì´ ì•„ë‹Œ, ìƒì„¸í•œ ë¶„ì„ì„ ìš”êµ¬í•˜ë„ë¡ í˜ë¥´ì†Œë‚˜ ê°•í™”
    prompt = ChatPromptTemplate.from_template(
        """
        You are a strict Security Officer for a publishing company. 
        Analyze the text for PII (names, addresses, IDs), hate speech, Sexual content, Dangerous activities, or inappropriate content.
        
        Text to analyze: {user_input}
        
        {format_instructions}
        """
    ).partial(format_instructions=parser.get_format_instructions()) # Parserê°€ ìƒì„±í•œ ì§€ì¹¨ ì‚½ì…
    
    # 4. ì²´ì¸ êµ¬ì„± ë° í˜¸ì¶œ
    # ë³€ê²½ ì‚¬í•­: StrOutputParser() ëŒ€ì‹  ìœ„ì—ì„œ ì •ì˜í•œ parserë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    chain = prompt | llm | parser

    try:
        # resultëŠ” ì´ì œ SafetyCheck í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤(ê°ì²´)ê°€ ë©ë‹ˆë‹¤.
        result = chain.invoke({"user_input": user_input})
        
        # 5. ì •ê·œí‘œí˜„ì‹ ê²°ê³¼ì™€ LLM ê²°ê³¼ ë³‘í•©
        # ë³€ê²½ ì‚¬í•­: LLMì´ ë†“ì¹  ìˆ˜ ìˆëŠ” ì •ê·œì‹ íŒ¨í„´(ì´ë©”ì¼ ë“±)ì„ ìµœì¢… ê²°ê³¼ì— ê°•ì œë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
        if found_emails:
            result.is_safe = False
            result.pii_detected = list(set(result.pii_detected + found_emails))
            result.reason += " [System] Email pattern detected via Regex."

    except Exception as e:
        # ğŸš¨ [í´ë°±] LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê°€ì¥ ë³´ìˆ˜ì ì¸(ì•ˆì „í•œ) íŒë‹¨ì„ ë‚´ë¦¼
        print(f"âŒ Safety Filter Error: {e}")
        result = SafetyCheck(
            is_safe=False, 
            reason="Safety check failed due to system error. (Fallback activated)",
            pii_detected=[]
        )

    print(f"ğŸ›¡ï¸ ì•ˆì „ì„± ê²°ê³¼: {'SAFE' if result.is_safe else 'UNSAFE'} (ì‚¬ìœ : {result.reason})")

    # 6. ìµœì¢… State ë°˜í™˜
    # ë³€ê²½ ì‚¬í•­: Aê°€ ì •ì˜í•œ state êµ¬ì¡°ì— ë§ì¶° 'safety_check'ì™€ ìƒì„¸ 'safety_detail'ì„ í•¨ê»˜ ë„˜ê¹ë‹ˆë‹¤.
    return {
        "safety_check": "SAFE" if result.is_safe else "UNSAFE",
        "safety_detail": result.model_dump(), # ìƒì„¸ ë°ì´í„°(ì‚¬ìœ , PII ëª©ë¡) ì €ì¥ (Pydantic V2ë¶€í„°ëŠ” .dict() ëŒ€ì‹  .model_dump()ë¥¼ ì‚¬ìš©. dict ë¹—ê¸ˆë°œìƒ)
        "logs": [f"Safety: {result.is_safe}, Reason: {result.reason}"]
    }
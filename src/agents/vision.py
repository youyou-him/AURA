import json
import os
import base64  # [ì¶”ê°€]
import io      # [ì¶”ê°€]
from PIL import Image
import google.generativeai as genai
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¤ì •
current_file_path = os.path.abspath(__file__)
tests_dir = os.path.dirname(current_file_path)
# .env íŒŒì¼ ìœ„ì¹˜ëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš” (ì˜ˆ: ìƒìœ„ í´ë” ë“±)
env_path = os.path.join(tests_dir, "..", "..", ".env") 
load_dotenv(dotenv_path=env_path)

# 2. API í‚¤ ì„¤ì •
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ [Vision] ì—ëŸ¬: GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    genai.configure(api_key=api_key)

def run_vision(state):
    print("--- [Vision Agent] ì´ë¯¸ì§€ ì •ë°€ ë¶„ì„ ì‹œì‘ (Gemini) ---")
    
    # Stateì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œì™€ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    image_data = state.get("image_data")
    user_text = state.get("user_input", "")

    # ëª¨ë¸ ì„¤ì • (Gemini 1.5 Flash ê¶Œì¥, ì—†ìœ¼ë©´ Pro ì‚¬ìš©)
    # user_textì— ì–¸ê¸‰ëœ 2.5 ëª¨ë¸ì€ ì•„ì§ ì •ì‹ ì‚¬ìš©ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ 1.5ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
    except:
        model = genai.GenerativeModel('gemini-2.5-flash')

    # ğŸ‘‡ [ìˆ˜ì •ë¨] ìš”ì²­í•˜ì‹  í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì ìš©í–ˆìŠµë‹ˆë‹¤.
    prompt = f"""
    You are the 'Chief Art Director'. 
    
    **[TASK: Step-by-Step Layout Decision]**
    Follow this exact order of thinking to decide "Overlay" vs "Separated".

    **STEP 1: Identify the 'HERO SUBJECT' (The Star)**
    - Read request: "{user_text}".
    - Find the Main Subject (Person, Watch, Bag).
    - **IGNORE** the background cleanliness for a moment. Focus ONLY on the Hero.

    **STEP 2: Analyze Hero's Dominance (The FATAL Check)**
    - **Is it a Person?** If yes, does the person occupy the **Center** of the image? -> If YES, STOP. Choose **'SEPARATED'**. (Never overlay text on a central portrait).
    - **Is it a Product?** Is it a "Macro Shot" (zoomed in extremely close)? -> If YES, STOP. Choose **'SEPARATED'**.
    - **Size Check:** Does the Hero Subject take up more than 50% of the image width/height? -> If YES, mostly **'SEPARATED'**.

    **STEP 3: Evaluate Background/Props (Only if Step 2 didn't stop you)**
    - Now look at the background.
    - **Case A (Prop as Canvas):** Is the Hero small, sitting on a huge uniform object (like a watch on a big white shell)? -> Choose **'OVERLAY'**.
    - **Case B (Clean Space):** Is the Hero off-center (Left/Right), leaving a huge empty sky/wall? -> Choose **'OVERLAY'**.

    **[Decision Logic Summary]**
    1. **Portrait/Central Human** = **SEPARATED** (Priority 1)
    2. **Zoomed-in Product** = **SEPARATED** (Priority 2)
    3. **Small Hero + Big Uniform Prop** = **OVERLAY** (Priority 3)
    4. **Small Hero + Clean Sky/Wall** = **OVERLAY** (Priority 4)

    **[JSON Data Structure]**
    1. thought_process: [
        "Step 1: Hero is 'Man'...",
        "Step 2: The Man is located in the center and fills 70% of the frame...",
        "Step 3: Background is white, BUT Step 2 (Central Portrait) overrides it...",
        "Step 4: Decision 'Separated' to protect the subject."
       ]
    2. layout_strategy:
        - recommendation: "Overlay" or "Separated"
        - reason: "Central portrait requires separation despite clean background."
    3. metadata: 
        - mood, dominant_colors, lighting
        - design_guide: text_contrast, font_recommendation
    4. safe_areas: [[ymin, xmin, ymax, xmax], ...] (Return [] if Separated)

    RETURN ONLY RAW JSON. NO MARKDOWN.

    **[JSON Response Example]**
    {{
        "thought_process": [
            "Step 1: User request is about a 'Watch'.",
            "Step 2: Found the Watch on the right side.",
            "Step 3: The large object on the left is a white Seashell (Prop).",
            "Step 4: The shell's surface is white and smooth.",
            "Step 5: Choosing 'Overlay' to place text on the shell."
        ],
        "layout_strategy": {{
            "recommendation": "Overlay",
            "reason": "Although the shell is large, it serves as a smooth, uniform background prop for the watch (Hero)."
        }},
        "metadata": {{
            "mood": "Oceanic, Luxury",
            "dominant_colors": ["#F5F5F5", "#003366", "#111111"],
            "lighting": "Soft studio light",
            "design_guide": {{
                "text_contrast": "Dark",
                "font_recommendation": "Sans-serif"
            }},
            "composition_analysis": {{
                "visual_weight": "Right-heavy (Watch)",
                "gaze_direction": "Left"
            }},
            "texture_context": {{
                "dominant_texture": "Smooth Shell Surface",
                "seasonal_vibe": "Summer"
            }}
        }},
        "safe_areas": [[100, 50, 800, 500]]
    }}
    
    RETURN ONLY RAW JSON. DO NOT USE MARKDOWN.
    """

    try:
        # ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] Base64 ë¬¸ìì—´ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ë¡œì§
        # 1. Base64 ë””ì½”ë”©
        image_bytes = base64.b64decode(image_data)
        
        # 2. Bytesë¥¼ ë©”ëª¨ë¦¬ íŒŒì¼(IO)ë¡œ ë³€í™˜ í›„ PILë¡œ ì—´ê¸°
        img = Image.open(io.BytesIO(image_bytes))
        
        # 3. Geminiì—ê²Œ ì „ì†¡
        response = model.generate_content([prompt, img])
        
        # JSON ì •ì œ
        json_res = response.text.replace("```json", "").replace("```", "").strip()
        return {"vision_result": json.loads(json_res)}
        
    except Exception as e:
        print(f"âŒ Vision Analysis Error: {e}")
        return {"vision_result": None}